{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2abede3-42db-4814-a73b-16dddf2467b6",
   "metadata": {},
   "source": [
    "Sample Questions:\n",
    "\n",
    "    Perform a t-test to compare income between genders.\n",
    "\n",
    "    Is there a significant relationship between education and employment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cee8f-a346-4a3d-a24a-69236bbbd75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(data[data['gender']=='M']['income'],\n",
    "          data[data['gender']=='F']['income'], nan_policy='omit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c02bb-8b08-4698-9c13-fd85645984bd",
   "metadata": {},
   "source": [
    "Is there a significant difference in income between males and females?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0fa0b-1fcf-4487-a090-98b987e3faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "male_income = data[data['gender'] == 'Male']['income'].dropna()\n",
    "female_income = data[data['gender'] == 'Female']['income'].dropna()\n",
    "\n",
    "t_stat, p_val = ttest_ind(male_income, female_income)\n",
    "print(f\"T-statistic: {t_stat:.3f}, P-value: {p_val:.3f}\")\n",
    "\n",
    "#ðŸ“Œ Interpretation:\n",
    "#If p < 0.05 â†’ statistically significant difference in mean income by gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa4654-c209-4a17-8223-4e300ad9f60e",
   "metadata": {},
   "source": [
    " ## 2. ANOVA: Compare More than Two Means\n",
    "\n",
    "Task:\n",
    "Assume we bin education_score into low, medium, high. Is there a difference in income across these groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbfee9-8e3f-4205-a2a5-49ee2a61eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Binning education_score\n",
    "data['edu_level'] = pd.qcut(data['education_score'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Perform ANOVA\n",
    "groups = [group['income'].dropna() for name, group in data.groupby('edu_level')]\n",
    "f_stat, p_val = f_oneway(*groups)\n",
    "print(f\"F-statistic: {f_stat:.3f}, P-value: {p_val:.3f}\")\n",
    "\n",
    "\n",
    "#ðŸ“Œ Interpretation:\n",
    "#p < 0.05 means income differs across education levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb1650-5cfc-4102-9374-e4923937396f",
   "metadata": {},
   "source": [
    "## 3. Chi-Square Test: Test Association Between Categorical Variables\n",
    "\n",
    "Task:\n",
    "Is there a significant association between gender and target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def8652-a4d0-40ed-890e-8361e18f2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(data['gender'], data['target'])\n",
    "chi2, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square: {chi2:.3f}, P-value: {p_val:.3f}\")\n",
    "\n",
    "#p < 0.05 â†’ gender and target are associated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e8b3c-e3ae-4ae3-b6ed-6115db57ee1b",
   "metadata": {},
   "source": [
    "## 4. Correlation Test: Linear Relationship Between Two Continuous Variables\n",
    "\n",
    "Task:\n",
    "Is there a significant correlation between income and education_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99791b85-8ca4-48e3-af55-b8409f37022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, p_val = pearsonr(data['income'].dropna(), data['education_score'].dropna())\n",
    "print(f\"Correlation: {corr:.3f}, P-value: {p_val:.3f}\")\n",
    "\n",
    "#Correlation near Â±1 = strong linear relationship.\n",
    "\n",
    "#p < 0.05 â†’ the correlation is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433b3aa-eb3f-4fac-b6f0-9037b29798e1",
   "metadata": {},
   "source": [
    "## 5. Bonus: Interpret a P-Value\n",
    "\n",
    "Question:\n",
    "\n",
    "# In a test comparing two means, you get a p-value of 0.01. What does this mean?\n",
    "\n",
    "ðŸ“Œ Answer (written):\n",
    "A p-value of 0.01 means there is a 1% probability that the observed difference (or a more extreme one) could occur by random chance if the null hypothesis is true. Since this is less than 0.05, we reject the null hypothesis and conclude the difference is statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2be734-fe13-4fb2-96af-faa883a5bb0e",
   "metadata": {},
   "source": [
    "âœ… 1. T-Test Interpretation\n",
    "\n",
    "# You performed a t-test comparing income between males and females and obtained a p-value of 0.03. What does this result suggest?\n",
    "\n",
    "Sample Answer:\n",
    "A p-value of 0.03 indicates that there is only a 3% chance that the observed difference in income between males and females occurred by random chance. Since the p-value is below the typical threshold of 0.05, we reject the null hypothesis and conclude that there is a statistically significant difference in income between genders in our sample.\n",
    "ðŸ§ª 2. ANOVA Interpretation\n",
    "\n",
    "# An ANOVA test comparing income across three education levels gave an F-statistic of 5.23 and a p-value of 0.007. What can we conclude?\n",
    "\n",
    "Sample Answer:\n",
    "The p-value of 0.007 is less than 0.05, suggesting that there is a statistically significant difference in average income across the three education level groups. However, ANOVA does not tell us which specific groups differ â€” for that, we would need to conduct a post-hoc test such as Tukey's HSD.\n",
    "ðŸ”— 3. Chi-Square Interpretation\n",
    "\n",
    "# You run a chi-square test between gender and target variable (0/1 outcome), and obtain a p-value of 0.12. What does this mean?\n",
    "\n",
    "Sample Answer:\n",
    "A p-value of 0.12 is greater than the common significance level of 0.05, meaning we fail to reject the null hypothesis. Therefore, we do not have enough evidence to conclude that there is an association between gender and the target outcome in this sample.\n",
    "ðŸ“ˆ 4. Correlation Interpretation\n",
    "\n",
    "# You find a Pearson correlation of 0.65 between education_score and income, with a p-value of 0.0001. What does this tell you?\n",
    "\n",
    "Sample Answer:\n",
    "A correlation coefficient of 0.65 indicates a moderately strong positive linear relationship between education score and income: as education score increases, income tends to increase as well. The very small p-value suggests this correlation is statistically significant and unlikely to be due to random chance.\n",
    "â“ 5. General: What Is a P-Value?\n",
    "\n",
    "# What is a p-value, and how should it be interpreted?\n",
    "\n",
    "Sample Answer:\n",
    "A p-value is the probability of observing data as extreme as, or more extreme than, what we observed, assuming the null hypothesis is true. A small p-value (typically < 0.05) suggests that the observed result is unlikely under the null hypothesis and provides evidence to reject it. However, it does not measure effect size or practical importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6318-c46d-40e5-a929-e5399faf818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'old_name1': 'new_name1',\n",
    "    'old_name2': 'new_name2'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50244041-c3c0-4ba7-bf45-68c4a57f5d82",
   "metadata": {},
   "source": [
    "## Detect Outliers, Add Flags to Original Data, Extract All Rows with Any Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8ced6-97a3-4ddd-9be0-2c8fdea1c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df):\n",
    "    outlier_flags = pd.DataFrame(index=df.index)\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outlier_flags[col + '_outlier'] = ~df[col].between(lower, upper)\n",
    "    \n",
    "    return outlier_flags\n",
    "\n",
    "#Add Flags to Original Data\n",
    "outlier_flags = detect_outliers_iqr(df)\n",
    "df_with_outliers = pd.concat([df, outlier_flags], axis=1)\n",
    "\n",
    "#Extract All Rows with Any Outlier\n",
    "# Get rows where at least one outlier is present\n",
    "outliers_only = df_with_outliers[outlier_flags.any(axis=1)]\n",
    "\n",
    "#Save Outliers to Excel Sheet\n",
    "outliers_only.to_excel(\"outliers_detected.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e301f28-c3e9-4be9-8a79-91430882f9fd",
   "metadata": {},
   "source": [
    "## Python Code: IQR Outlier Detection for All Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0965f-5d1e-4ed4-aa9c-044fbae6fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_outliers_iqr(df):\n",
    "    outlier_flags = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Only apply to numeric columns\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Create a boolean mask for outliers\n",
    "        outlier_flags[col + '_outlier'] = ~df[col].between(lower, upper)\n",
    "    \n",
    "    return outlier_flags\n",
    "\n",
    "\n",
    "# Apply to your cleaned data\n",
    "outliers_df = detect_outliers_iqr(df)\n",
    "\n",
    "# Count outliers per column\n",
    "outliers_df.sum()\n",
    "\n",
    "#Add Outlier Info to Original DataFrame\n",
    "\n",
    "df_with_flags = pd.concat([df, detect_outliers_iqr(df)], axis=1)\n",
    "\n",
    "#Remove All Outliers\n",
    "\n",
    "mask = ~detect_outliers_iqr(df).any(axis=1)\n",
    "df_no_outliers = df[mask]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
